contrast = c("group", "grp2", "grp1"),
expand = TRUE)
my_methods <- c(my_limma, my_ALDEx2)
View(my_methods)
DA_custom <- function(
object,
contrast = NULL,
paired = FALSE,
verbose = TRUE)
{
name <- "custom"
# Read the counts
counts_and_metadata <- get_counts_metadata(object)
counts <- counts_and_metadata[[1]]
metadata <- counts_and_metadata[[2]]
# Log transform data
if(verbose){
message("Log transform the counts")
}
logcounts <- log1p(counts)
# Check if contrast vector is present
# We need it to understand what to test
if(is.null(contrast)){
stop("Please supply a contrast vector")
}
# Look for samples of the first and second group
group1 <- which(metadata[, contrast[1]] == contrast[2])
group2 <- which(metadata[, contrast[1]] == contrast[3])
if(paired){
# Check if the number of samples in the groups is equal
if(length(group1) != length(group2)){
stop(method, "\n", "paired = TRUE but ",
contrast[2], " and ", contrast[3], " have ",
length(group1), " and ", length(group2),
" samples respectively.")
}
if(verbose){
message("Performing the analysis on paired data")
}
# Update the name
name <- paste(name, ".", "paired", sep = "")
}
if(verbose){
message("Performing t.tests")
}
# Perform the tests
statInfo_list <- apply(
X = logcounts,
MARGIN = 1,
FUN = function(feature){
if(!paired){
# Compute the average values for each group
avg_group1 <- mean(feature[group1])
avg_group2 <- mean(feature[group2])
# Compute the logFC
logFC <- avg_group1 - avg_group2
} else {
# Compute the average difference for each group
logFC <- mean(feature[group1] - feature[group2])
}
# Perform the t-test
results <- stats::t.test(
x = feature[group1],
y = feature[group2],
paired = paired)
# Prepare the output
out <- data.frame(
logFC,
"statistic" = results[["statistic"]],
"pvalue" = results[["p.value"]],
"lowCI" = results[["conf.int"]][1],
"uppCI" = results[["conf.int"]][2])
return(out)
}
)
# Transform the list into a data.frame
statInfo <- plyr::ldply(statInfo_list)
# Rename the columns
colnames(statInfo)[1] <- "taxon"
# Create pValMat
padj <- stats::p.adjust(p = statInfo$pvalue, method = "BH")
pValMat <- data.frame("rawP" = statInfo[, "pvalue"], "adjP" = padj)
# Add rownames
rownames(statInfo) <- rownames(pValMat) <- statInfo[, 1]
# Return statInfo, pValMat and a name
return(list(
"pValMat" = pValMat,
"statInfo" = statInfo,
"name" = name))
}
my_custom_method <- list(
customMethod.1 = list(
method = "DA_custom",
contrast = c("group", "grp2", "grp1"),
paired = FALSE)
)
# Add the custom method instances to the others
my_methods <- c(my_methods, my_custom_method)
# Random grouping each time
sup_mockDA <- runMocks(
mocks = my_mocks,
method_list = my_methods,
object = ps_sup_filtered,
verbose = FALSE)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(benchdamic)
# Data management
library(phyloseq)
# Graphics and tables
library(ggplot2)
library(cowplot)
library(kableExtra)
data("ps_plaque_16S")
ps_plaque_16S
# Subset Supragingival Plaque samples
ps_sup <- phyloseq::subset_samples(ps_plaque_16S, HMP_BODY_SUBSITE == "Supragingival Plaque")
# Remove taxa with all zeroes
ps_sup <- phyloseq::filter_taxa(ps_sup, function(x) sum(x > 0) > 0, TRUE)
GOF_plaque_16S <- fitModels(
object = ps_sup,
models = c("NB", "ZINB", "DM", "ZIG", "HURDLE"),
scale_HURDLE = c("median"),
verbose = FALSE # TRUE is always suggested
)
plotMD(
data = GOF_plaque_16S,
difference = "MD",
split = TRUE
)
plotMD(
data = GOF_plaque_16S,
difference = "ZPD",
split = TRUE
)
available_methods <- read.csv(file = "./benchdamic_methods.csv", sep = ";")
kableExtra::kable(
x = available_methods,
caption = "DA methods available in benchdamic.",
col.names = c("Method (package)", "Short description", "Test",
"Normalization / Transformation", "Suggested input", "Output"),
booktabs = TRUE) %>%
kable_styling(latex_options = "scale_down") %>%
row_spec(0, bold = TRUE, color = "black") %>%
column_spec(c(1,5,6), width = "3cm") %>%
column_spec(2:4, width = "6cm") %>%
column_spec(1:6, color = "black")
set.seed(123)
my_mocks <- createMocks(
nsamples = phyloseq::nsamples(ps_sup),
N = 10
) # At least N = 1000 is suggested
# Set the instructions
my_normalizations <- setNormalizations(
fun = c("norm_edgeR"),
method = c("TMM"))
# Add the normalization/scaling factors to the object
ps_sup <- runNormalizations(
normalization_list = my_normalizations,
object = ps_sup,
verbose = TRUE)
ps_sup_filtered <- phyloseq::filter_taxa(
physeq = ps_sup,
flist = function(x) sum(x > 0) >= 3,
prune = TRUE)
ps_sup_filtered
DA_custom <- function(
object,
contrast = NULL,
paired = FALSE,
verbose = TRUE)
{
name <- "custom"
# Read the counts
counts_and_metadata <- get_counts_metadata(object)
counts <- counts_and_metadata[[1]]
metadata <- counts_and_metadata[[2]]
# Log transform data
if(verbose){
message("Log transform the counts")
}
logcounts <- log1p(counts)
# Check if contrast vector is present
# We need it to understand what to test
if(is.null(contrast)){
stop("Please supply a contrast vector")
}
# Look for samples of the first and second group
group1 <- which(metadata[, contrast[1]] == contrast[2])
group2 <- which(metadata[, contrast[1]] == contrast[3])
if(paired){
# Check if the number of samples in the groups is equal
if(length(group1) != length(group2)){
stop(method, "\n", "paired = TRUE but ",
contrast[2], " and ", contrast[3], " have ",
length(group1), " and ", length(group2),
" samples respectively.")
}
if(verbose){
message("Performing the analysis on paired data")
}
# Update the name
name <- paste(name, ".", "paired", sep = "")
}
if(verbose){
message("Performing t.tests")
}
# Perform the tests
statInfo_list <- apply(
X = logcounts,
MARGIN = 1,
FUN = function(feature){
if(!paired){
# Compute the average values for each group
avg_group1 <- mean(feature[group1])
avg_group2 <- mean(feature[group2])
# Compute the logFC
logFC <- avg_group1 - avg_group2
} else {
# Compute the average difference for each group
logFC <- mean(feature[group1] - feature[group2])
}
# Perform the t-test
results <- stats::t.test(
x = feature[group1],
y = feature[group2],
paired = paired)
# Prepare the output
out <- data.frame(
logFC,
"statistic" = results[["statistic"]],
"pvalue" = results[["p.value"]],
"lowCI" = results[["conf.int"]][1],
"uppCI" = results[["conf.int"]][2])
return(out)
}
)
# Transform the list into a data.frame
statInfo <- plyr::ldply(statInfo_list)
# Rename the columns
colnames(statInfo)[1] <- "taxon"
# Create pValMat
padj <- stats::p.adjust(p = statInfo$pvalue, method = "BH")
pValMat <- data.frame("rawP" = statInfo[, "pvalue"], "adjP" = padj)
# Add rownames
rownames(statInfo) <- rownames(pValMat) <- statInfo[, 1]
# Return statInfo, pValMat and a name
return(list(
"pValMat" = pValMat,
"statInfo" = statInfo,
"name" = name))
} # END - function: DA_custom
my_custom_method <- list(
customMethod.1 = list(
method = "DA_custom",
contrast = c("group", "grp2", "grp1"),
paired = FALSE)
)
# Add the custom method instances to the others
my_methods <- c(my_methods, my_custom_method)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(benchdamic)
# Data management
library(phyloseq)
# Graphics and tables
library(ggplot2)
library(cowplot)
library(kableExtra)
data("ps_plaque_16S")
ps_plaque_16S
# Subset Supragingival Plaque samples
ps_sup <- phyloseq::subset_samples(ps_plaque_16S, HMP_BODY_SUBSITE == "Supragingival Plaque")
# Remove taxa with all zeroes
ps_sup <- phyloseq::filter_taxa(ps_sup, function(x) sum(x > 0) > 0, TRUE)
GOF_plaque_16S <- fitModels(
object = ps_sup,
models = c("NB", "ZINB", "DM", "ZIG", "HURDLE"),
scale_HURDLE = c("median"),
verbose = FALSE # TRUE is always suggested
)
plotMD(
data = GOF_plaque_16S,
difference = "MD",
split = TRUE
)
plotMD(
data = GOF_plaque_16S,
difference = "ZPD",
split = TRUE
)
available_methods <- read.csv(file = "./benchdamic_methods.csv", sep = ";")
kableExtra::kable(
x = available_methods,
caption = "DA methods available in benchdamic.",
col.names = c("Method (package)", "Short description", "Test",
"Normalization / Transformation", "Suggested input", "Output"),
booktabs = TRUE) %>%
kable_styling(latex_options = "scale_down") %>%
row_spec(0, bold = TRUE, color = "black") %>%
column_spec(c(1,5,6), width = "3cm") %>%
column_spec(2:4, width = "6cm") %>%
column_spec(1:6, color = "black")
set.seed(123)
my_mocks <- createMocks(
nsamples = phyloseq::nsamples(ps_sup),
N = 10
) # At least N = 1000 is suggested
# Set the instructions
my_normalizations <- setNormalizations(
fun = c("norm_edgeR"),
method = c("TMM"))
# Add the normalization/scaling factors to the object
ps_sup <- runNormalizations(
normalization_list = my_normalizations,
object = ps_sup,
verbose = TRUE)
ps_sup_filtered <- phyloseq::filter_taxa(
physeq = ps_sup,
flist = function(x) sum(x > 0) >= 3,
prune = TRUE)
ps_sup_filtered
DA_custom <- function(
object,
contrast = NULL,
paired = FALSE,
verbose = TRUE)
{
name <- "custom"
# Read the counts
counts_and_metadata <- get_counts_metadata(object)
counts <- counts_and_metadata[[1]]
metadata <- counts_and_metadata[[2]]
# Log transform data
if(verbose){
message("Log transform the counts")
}
logcounts <- log1p(counts)
# Check if contrast vector is present
# We need it to understand what to test
if(is.null(contrast)){
stop("Please supply a contrast vector")
}
# Look for samples of the first and second group
group1 <- which(metadata[, contrast[1]] == contrast[2])
group2 <- which(metadata[, contrast[1]] == contrast[3])
if(paired){
# Check if the number of samples in the groups is equal
if(length(group1) != length(group2)){
stop(method, "\n", "paired = TRUE but ",
contrast[2], " and ", contrast[3], " have ",
length(group1), " and ", length(group2),
" samples respectively.")
}
if(verbose){
message("Performing the analysis on paired data")
}
# Update the name
name <- paste(name, ".", "paired", sep = "")
}
if(verbose){
message("Performing t.tests")
}
# Perform the tests
statInfo_list <- apply(
X = logcounts,
MARGIN = 1,
FUN = function(feature){
if(!paired){
# Compute the average values for each group
avg_group1 <- mean(feature[group1])
avg_group2 <- mean(feature[group2])
# Compute the logFC
logFC <- avg_group1 - avg_group2
} else {
# Compute the average difference for each group
logFC <- mean(feature[group1] - feature[group2])
}
# Perform the t-test
results <- stats::t.test(
x = feature[group1],
y = feature[group2],
paired = paired)
# Prepare the output
out <- data.frame(
logFC,
"statistic" = results[["statistic"]],
"pvalue" = results[["p.value"]],
"lowCI" = results[["conf.int"]][1],
"uppCI" = results[["conf.int"]][2])
return(out)
}
)
# Transform the list into a data.frame
statInfo <- plyr::ldply(statInfo_list)
# Rename the columns
colnames(statInfo)[1] <- "taxon"
# Create pValMat
padj <- stats::p.adjust(p = statInfo$pvalue, method = "BH")
pValMat <- data.frame("rawP" = statInfo[, "pvalue"], "adjP" = padj)
# Add rownames
rownames(statInfo) <- rownames(pValMat) <- statInfo[, 1]
# Return statInfo, pValMat and a name
return(list(
"pValMat" = pValMat,
"statInfo" = statInfo,
"name" = name))
} # END - function: DA_custom
my_custom_method <- list(
customMethod.1 = list(
method = "DA_custom",
contrast = c("group", "grp2", "grp1"),
paired = FALSE)
)
# Add the custom method instances to the others
my_methods <- c(my_methods, my_custom_method)
# Random grouping each time
sup_mockDA <- runMocks(
mocks = my_mocks,
method_list = my_methods,
object = ps_sup_filtered,
verbose = FALSE)
View(sup_mockDA)
TIEC_summary <- createTIEC(sup_mockDA)
cols <- createColors(
variable = levels(TIEC_summary$df_FPR$Method))
plotFPR(df_FPR = TIEC_summary$df_FPR, cols = cols)
# Set the HMP_BODY_SUBSITE and RSID variable as factors
sample_data(ps_plaque_16S)$HMP_BODY_SUBSITE <-
factor(sample_data(ps_plaque_16S)$HMP_BODY_SUBSITE)
sample_data(ps_plaque_16S)$RSID <-
factor(sample_data(ps_plaque_16S)$RSID)
# Set a seed for reproducibility
set.seed(123)
my_splits <- createSplits(
object = ps_plaque_16S,
varName = "HMP_BODY_SUBSITE",
paired = "RSID",
balanced = TRUE,
N = 10
) # At least 100 is suggested
available_methods <- read.csv(file = "./benchdamic_methods.csv", sep = ";")
kableExtra::kable(
x = available_methods,
caption = "DA methods available in benchdamic.",
col.names = c("Method (package)", "Short description", "Test",
"Normalization / Transformation", "Suggested input", "Output"),
booktabs = TRUE) %>%
kable_styling(latex_options = "scale_down") %>%
row_spec(0, bold = TRUE, color = "black") %>%
column_spec(c(1,5,6), width = "3cm") %>%
column_spec(2:4, width = "6cm") %>%
column_spec(1:6, color = "black")
library(kableExtra)
available_methods <- read.csv(file = "./benchdamic_methods.csv", sep = ";")
kableExtra::kable(
x = available_methods,
caption = "DA methods available in benchdamic.",
col.names = c("Method (package)", "Short description", "Test",
"Normalization / Transformation", "Suggested input", "Output"),
booktabs = TRUE) %>%
kable_styling(latex_options = "scale_down") %>%
row_spec(0, bold = TRUE, color = "black") %>%
column_spec(c(1,5,6), width = "3cm") %>%
column_spec(2:4, width = "6cm") %>%
column_spec(1:6, color = "black")
available_methods <- read.csv(file = "./benchdamic_methods.csv", sep = ";")
kableExtra::kable(
x = available_methods,
caption = "DA methods available in benchdamic.",
col.names = c("Method (package)", "Short description", "Test",
"Normalization / Transformation", "Suggested input", "Output", "Application"),
booktabs = TRUE) %>%
kable_styling(latex_options = "scale_down") %>%
row_spec(0, bold = TRUE, color = "black") %>%
column_spec(c(1,5,6), width = "3cm") %>%
column_spec(2:4, width = "6cm") %>%
column_spec(1:6, color = "black")
setwd("~/Documents/GitHub/benchdamicWorkshop")
Firstly we load some packages for basic functions and data:
Firstly we load some packages for basic functions and data:
library(benchdamic)
# Data management
library(phyloseq)
# Graphics and tables
library(ggplot2)
library(cowplot)
library(kableExtra)
data("ps_plaque_16S")
ps_plaque_16S
# Subset Supragingival Plaque samples
ps_sup <- phyloseq::subset_samples(ps_plaque_16S, HMP_BODY_SUBSITE == "Supragingival Plaque")
# Remove taxa with all zeroes
ps_sup <- phyloseq::filter_taxa(ps_sup, function(x) sum(x > 0) > 0, TRUE)
GOF_plaque_16S <- fitModels(
object = ps_sup,
models = c("NB", "ZINB", "DM", "ZIG", "HURDLE"),
scale_HURDLE = c("median"),
verbose = FALSE # TRUE is always suggested
)
plotMD(
data = GOF_plaque_16S,
difference = "MD",
split = TRUE
)
devtools::install_github("mcalgaro93/benchdamicWorkshop")
library(benchdamicWorkshop)
vignette("benchdamicWorkshop")
